{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXpkXz1QJmhJ"
      },
      "source": [
        "Soft deadline: `30.03.2022 23:59`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxy7euTpCbGp"
      },
      "source": [
        "In this homework you will understand the fine-tuning procedure and get acquainted with Huggingface Datasets library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1MXcMymXeCx"
      },
      "outputs": [],
      "source": [
        "! pip install datasets\n",
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FykUK-TFXf-2"
      },
      "source": [
        "For our goals we will use [Datasets](https://huggingface.co/docs/datasets/) library and take `yahoo_answers_topics` dataset - the task of this dataset is to divide documents on 10 topic categories. More detiled information can be found on the dataset [page](https://huggingface.co/datasets/viewer/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ebsFAQsgXNB0"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UbzxZi42XOUG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset yahoo_answers_topics (C:\\Users\\sorok\\.cache\\huggingface\\datasets\\yahoo_answers_topics\\yahoo_answers_topics\\1.0.0\\b2712a72fde278f1d6e96cc4f485fd89ed2f79ecb231441e13645b53da021902)\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.32it/s]\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset('yahoo_answers_topics') # the result is a dataset dictionary of train and test splits in this case"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U4YUOB5W8uG"
      },
      "source": [
        "# Fine-tuning the model** (20 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZDYIq9l7CYBR"
      },
      "outputs": [],
      "source": [
        "from transformers import (ElectraTokenizer, ElectraForSequenceClassification,\n",
        "                          get_scheduler, pipeline, ElectraForMaskedLM, ElectraModel)\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElZ6k36rb0VG"
      },
      "source": [
        "Fine-tuning procedure on the end task consists of adding additional layers on the top of the pre-trained model. The resulting model can be tuned fully (passing gradients through the all model) or partially."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNEmksaPb3Uu"
      },
      "source": [
        "**Task**: \n",
        "- load tokenizer and model\n",
        "- look at the predictions of the model as-is before any fine-tuning\n",
        "\n",
        "\n",
        "```\n",
        "- Why don't you ask [MASK]?\n",
        "- What is [MASK]\n",
        "- Let's talk about [MASK] physics\n",
        "```\n",
        "\n",
        "- convert `best_answer` to the input tokens (supporting function for dataset is provided below) \n",
        "\n",
        "```\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"best_answer\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "```\n",
        "\n",
        "- define optimizer, sheduler (optional)\n",
        "- fine-tune the model (write the training loop), plot the loss changes and measure results in terms of weighted F1 score\n",
        "- get the masked word prediction (sample sentences above) on the fine-tuned model, why the results as they are and what should be done in order to change that (write down your answer)\n",
        "- Tune the training hyperparameters (and write down your results).\n",
        "\n",
        "**Tips**:\n",
        "- The easiest way to get predictions is to use transformers `pipeline` function \n",
        "- Do not forget to set `num_labels` parameter, when initializing the model\n",
        "- To convert data to batches use `DataLoader`\n",
        "- Even the `small` version of Electra can be long to train, so you can take data sample (>= 5000 and set seed for reproducibility)\n",
        "- You may want to try freezing (do not update the pretrained model weights) all the layers exept the ones for classification, in that case use:\n",
        "\n",
        "\n",
        "```\n",
        "for param in model.electra.parameters():\n",
        "      param.requires_grad = False\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "\"topic\":\n",
        "0:\"Society & Culture\"\n",
        "1:\"Science & Mathematics\"\n",
        "2:\"Health\"\n",
        "3:\"Education & Reference\"\n",
        "4:\"Computers & Internet\"\n",
        "5:\"Sports\"\n",
        "6:\"Business & Finance\"\n",
        "7:\"Entertainment & Music\"\n",
        "8:\"Family & Relationships\"\n",
        "9:\"Politics & Government\"\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 0,\n",
              " 'topic': 4,\n",
              " 'question_title': \"why doesn't an optical mouse work on a glass table?\",\n",
              " 'question_content': 'or even on some surfaces?',\n",
              " 'best_answer': 'Optical mice use an LED and a camera to rapidly capture images of the surface beneath the mouse.  The infomation from the camera is analyzed by a DSP (Digital Signal Processor) and used to detect imperfections in the underlying surface and determine motion. Some materials, such as glass, mirrors or other very shiny, uniform surfaces interfere with the ability of the DSP to accurately analyze the surface beneath the mouse.  \\\\nSince glass is transparent and very uniform, the mouse is unable to pick up enough imperfections in the underlying surface to determine motion.  Mirrored surfaces are also a problem, since they constantly reflect back the same image, causing the DSP not to recognize motion properly. When the system is unable to see surface changes associated with movement, the mouse will not work properly.'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = dataset.remove_columns(['id'])\n",
        "dataset = dataset.rename_column(\"topic\", \"labels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'labels': 4,\n",
              " 'question_title': \"why doesn't an optical mouse work on a glass table?\",\n",
              " 'question_content': 'or even on some surfaces?',\n",
              " 'best_answer': 'Optical mice use an LED and a camera to rapidly capture images of the surface beneath the mouse.  The infomation from the camera is analyzed by a DSP (Digital Signal Processor) and used to detect imperfections in the underlying surface and determine motion. Some materials, such as glass, mirrors or other very shiny, uniform surfaces interfere with the ability of the DSP to accurately analyze the surface beneath the mouse.  \\\\nSince glass is transparent and very uniform, the mouse is unable to pick up enough imperfections in the underlying surface to determine motion.  Mirrored surfaces are also a problem, since they constantly reflect back the same image, causing the DSP not to recognize motion properly. When the system is unable to see surface changes associated with movement, the mouse will not work properly.'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8yqAAFqZcwbu"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"google/electra-small-generator\"\n",
        "TOKENIZER_NAME = \"google/electra-small-generator\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "fill_mask = pipeline(\n",
        "    'fill-mask',\n",
        "    model = MODEL_NAME,\n",
        "    tokenizer = TOKENIZER_NAME\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "why don't you ask me?\n"
          ]
        }
      ],
      "source": [
        "print(fill_mask(\"Why don't you ask [MASK]?\")[0]['sequence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what is?\n"
          ]
        }
      ],
      "source": [
        "print(fill_mask(\"What is [MASK]\")[0]['sequence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "let's talk about quantum physics\n"
          ]
        }
      ],
      "source": [
        "print(fill_mask(\"Let's talk about [MASK] physics\")[0]['sequence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at C:\\Users\\sorok\\.cache\\huggingface\\datasets\\yahoo_answers_topics\\yahoo_answers_topics\\1.0.0\\b2712a72fde278f1d6e96cc4f485fd89ed2f79ecb231441e13645b53da021902\\cache-65a3dc4fc6bf8cf0.arrow\n",
            "100%|██████████| 60/60 [00:13<00:00,  4.57ba/s]\n"
          ]
        }
      ],
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"best_answer\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['labels', 'question_title', 'question_content', 'best_answer', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "    num_rows: 1400000\n",
              "})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_datasets.set_format(\"torch\")\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['question_title', 'question_content', 'best_answer'])\n",
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=123).select(range(5000))\n",
        "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=123).select(range(5000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "    num_rows: 5000\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "small_train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)\n",
        "eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/electra-small-generator were not used when initializing ElectraForSequenceClassification: ['generator_predictions.LayerNorm.bias', 'generator_predictions.dense.bias', 'generator_lm_head.weight', 'generator_predictions.dense.weight', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-generator and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "class_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(class_model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_epochs = 5\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ElectraForSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ElectraClassificationHead(\n",
              "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "class_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 1/5 [01:50<07:22, 110.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            " Current loss 1.8059033155441284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 2/5 [03:36<05:24, 108.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            " Current loss 1.3049064874649048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [05:23<03:35, 107.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2\n",
            " Current loss 1.0746718645095825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 4/5 [07:10<01:47, 107.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3\n",
            " Current loss 0.9108606576919556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [08:56<00:00, 107.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4\n",
            " Current loss 0.7766764760017395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "losses_on_epochs = []\n",
        "class_model.train()\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    losses = []\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = class_model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        losses.append(loss)\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "    losses_on_epochs.append(torch.mean(torch.tensor(losses)))\n",
        "    print(f\"Epoch {epoch}\\n Current loss {torch.mean(torch.tensor(losses))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses_on_epochs)\n",
        "plt.title(\"Losses by epochs\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'f1': 0.5686687188780158}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric = load_metric(\"f1\")\n",
        "class_model.eval()\n",
        "for batch in eval_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = class_model(**batch)\n",
        "    \n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "metric.compute(average = 'weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_model.save_pretrained(\"C:/Users/sorok/Desktop/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at C:/Users/sorok/Desktop/ were not used when initializing ElectraForMaskedLM: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "- This IS expected if you are initializing ElectraForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForMaskedLM were not initialized from the model checkpoint at C:/Users/sorok/Desktop/ and are newly initialized: ['generator_predictions.LayerNorm.bias', 'generator_predictions.dense.bias', 'generator_lm_head.weight', 'generator_predictions.dense.weight', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "new_mask_model = ElectraForMaskedLM.from_pretrained(\"C:/Users/sorok/Desktop/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "fill_mask2 = pipeline(\n",
        "    'fill-mask',\n",
        "    model = new_mask_model,\n",
        "    tokenizer = TOKENIZER_NAME\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "why don't you ask gemini?\n"
          ]
        }
      ],
      "source": [
        "print(fill_mask2(\"Why don't you ask [MASK]?\")[0]['sequence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what isbas\n"
          ]
        }
      ],
      "source": [
        "print(fill_mask2(\"What is [MASK]\")[0]['sequence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "let's talk about inquired physics\n"
          ]
        }
      ],
      "source": [
        "print(fill_mask2(\"Let's talk about [MASK] physics\")[0]['sequence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'score': 0.0003597834147512913, 'token': 24849, 'token_str': 'inquired', 'sequence': \"let's talk about inquired physics\"}, {'score': 0.0002826803538482636, 'token': 4596, 'token_str': 'dinner', 'sequence': \"let's talk about dinner physics\"}, {'score': 0.00026624195743352175, 'token': 4977, 'token_str': 'turkey', 'sequence': \"let's talk about turkey physics\"}, {'score': 0.00026534197968430817, 'token': 17413, 'token_str': '##cky', 'sequence': \"let's talk aboutcky physics\"}, {'score': 0.0002448171435389668, 'token': 22878, 'token_str': 'midday', 'sequence': \"let's talk about midday physics\"}]\n"
          ]
        }
      ],
      "source": [
        "print(fill_mask2(\"Let's talk about [MASK] physics\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# With the selected hyperparameters it was possible to achieve f1 = 56 score which is decent, classification is successful.\n",
        "# It seems like the resulted mask model is kinda random. It have too low % chances for specific words.\n",
        "# This may occur because I trained the whole model and not just the extra layer. The model focused on learning\n",
        "# the classification task and mixed all weights and biases for the mask model, thus it doesn't work anymore."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "hw4 (3).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
